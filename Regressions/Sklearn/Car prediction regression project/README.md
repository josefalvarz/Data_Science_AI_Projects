- This project uses Regression to predict prices of cars on a dataset containing price and characteristics of used cars. This project went through multiple stages like data cleaning in which I dealt with missing values and outliers. I've also checked the linearity assuptioms specially for Linearity and Multicollinearity. Finally I analyzed the data using several graphs using matplotlib and seaborn. There are other important concepts such as standarization and split of data that were used in the project in which you can check in the 'Regression Projct' file.

- The model explains 75% of the variability of the dataset, which is not bad but can be improved. An important observation that I saw in the model is that it predicts great when cars prices are high, but it performs poorly when predicting prices of cheap cars which this leads that there is a key factor that drives cheap cars lower, maybe they are damaged.

- The 'Regression Project removing 'EngineV' and 'Registration_yes' is a file that shows what will happen if we remove two variables that have a bit high degree of multicollinearity (EngineV and Registration_yes). The results showed that instead of improving the predicting power of the model it demostrated a decrease in score which was 60% in comparison of 75% .The conclusion is that this two variables are significant because of that factor and that their p_value is quite low (<0.05).

- The third file is a case where the 'model' feature was never removed. The model was evaluated on test data (I splitted the data) and the score was 82% which is a great improvement from 75%, but when I checked the predictions and analyzed the model in a graph it shows that the predictions were huge (intercept was 146,310,314,834). The conclusion was that the model is with extreme high multicollinearity and overfitted. Therefore we need to remove'model' (312 dummies).